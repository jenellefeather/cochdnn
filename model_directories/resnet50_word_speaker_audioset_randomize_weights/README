ResNet50 architecture with a cochleagram input. Trained to perform the audioset environmental sound recognition task. Weights are randomized to extract the neural activations

Trained by jfeather on openmind cluster using 4 tesla-v100 GPUs (DGX machine)  and a total batch size of 256. Learning rate started at 0.001 and was dropped by a factor of 10 after every 14 epochs of the audioset task (50 epochs of the word task to match word training). SGD optimizer was used with a momentum of 0.9 and weight decay of 1e-4 and gradients were clipped to have a maximum L2 norm of 1.0. The BinaryCrossEntropy loss was scaled by a factor of 300 during training. The model was trained for a total of 42 Epochs of Audioset data from WSN corresponding to 150 Epochs of the speech data from WSN (each speech sample was paired with random audioset background, but no speech task was included). Augmentation during training consisted of jittering in time (ie random crop while keeping the word overlapping with the middle) and background noise varied between -10dB and 10dB SNR. 

